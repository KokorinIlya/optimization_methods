{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import sklearn.model_selection\n",
    "from HW1.logit import Logit\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "    data = pd.read_csv(path)\n",
    "    X = data.iloc[:,:-1].values\n",
    "    y = data.iloc[:, -1].apply(lambda c: 1 if c == 'P' else -1).values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_f_score(X, y, alpha, solver, debug_iters):\n",
    "    n_splits = 5\n",
    "    cv = sklearn.model_selection.KFold(n_splits=n_splits, shuffle=True)\n",
    "    mean_f_score = 0.0\n",
    "    for train_indexes, test_indexes in cv.split(X):\n",
    "        X_train = X[train_indexes]\n",
    "        X_test = X[test_indexes]\n",
    "        y_train = y[train_indexes]\n",
    "        y_test = y[test_indexes]\n",
    "\n",
    "        classifier = Logit(alpha, solver)\n",
    "        classifier.fit(X_train, y_train, debug_iters)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        tp = np.sum((y_pred == 1) & (y_test == 1))\n",
    "        fp = np.sum((y_pred == 1) & (y_test != 1))\n",
    "        tn = np.sum((y_pred != 1) & (y_test != 1))\n",
    "        fn = np.sum((y_pred != 1) & (y_test == 1))\n",
    "\n",
    "        if tp != 0:\n",
    "            precision = tp / (tp + fp)\n",
    "            recall = tp / (tp + fn)\n",
    "            f_score = 2 * precision * recall / (precision + recall)\n",
    "            mean_f_score += f_score\n",
    "    return mean_f_score / n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_param(X, y, solver, debug_iters):\n",
    "    best_alpha = None\n",
    "    max_f_score = -1\n",
    "    for alpha in [0.0001, 0.001, 0.01, 0.1, 1.]:\n",
    "        cur_f_score = calc_f_score(X, y, alpha, solver, debug_iters)\n",
    "        print('alpha =', alpha, 'f-score =', cur_f_score)\n",
    "        if cur_f_score > max_f_score:\n",
    "            max_f_score = cur_f_score\n",
    "            best_alpha = alpha\n",
    "    return best_alpha, max_f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(clf, X, ans, step_x, step_y):\n",
    "    x_min, y_min = np.amin(X, axis = 0)\n",
    "    x_max, y_max = np.amax(X, axis = 0)\n",
    "    x_min -= step_x\n",
    "    x_max += step_x\n",
    "    y_min -= step_y\n",
    "    y_max += step_y\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, step_x), np.arange(y_min, y_max, step_y))\n",
    "    \n",
    "    zz = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    \n",
    "    x0, y0 = X[ans != 1].T\n",
    "    x1, y1 = X[ans == 1].T\n",
    "\n",
    "    plt.pcolormesh(xx, yy, zz, cmap=matplotlib.colors.ListedColormap(['#FFAAAA', '#AAAAFF']))\n",
    "    plt.scatter(x0, y0, color='red', s=100)\n",
    "    plt.scatter(x1, y1, color='blue', s=100)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_with_solver(X, y, solver, step_x, step_y, debug_iters=None):\n",
    "    best_alpha, max_f_score = get_best_param(X, y, solver, debug_iters)\n",
    "    print('Best params:', best_alpha, max_f_score)\n",
    "    best_classifier = Logit(best_alpha, solver)\n",
    "    start_time = datetime.now()\n",
    "    number_of_steps = best_classifier.fit(X, y, debug_iters=debug_iters)\n",
    "    end_time = datetime.now()\n",
    "    timedelta = end_time - start_time\n",
    "    if solver == 'newton':\n",
    "        print('errors =', number_of_steps.errors, 'steps =', number_of_steps.steps)\n",
    "    else:\n",
    "        print('steps =', number_of_steps.steps)\n",
    "    print('time =', timedelta.microseconds, 'microseconds')\n",
    "    draw(best_classifier, X, y, step_x, step_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = read_dataset('data/geyser.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 1000 grad = [-0.00464144 -0.00090692 -0.00097621] ||grad|| = 0.004828921551180213\n",
      "iteration = 2000 grad = [-1.54446147e-04 -3.10531480e-05 -2.96792634e-05] ||grad|| = 0.00016030835603089065\n",
      "iteration = 1000 grad = [ 0.00446707  0.00126516 -0.00037979] ||grad|| = 0.004658278984811304\n",
      "iteration = 2000 grad = [ 1.55227126e-04  4.41017762e-05 -1.29780478e-05] ||grad|| = 0.00016189149817404325\n",
      "iteration = 1000 grad = [-0.00735265 -0.00138452 -0.00176316] ||grad|| = 0.0076868162301979275\n",
      "iteration = 2000 grad = [-4.71998635e-04 -9.09411015e-05 -1.08054152e-04] ||grad|| = 0.0004926750398847003\n",
      "iteration = 1000 grad = [ 0.00655028  0.00181027 -0.00062579] ||grad|| = 0.006824583128068837\n",
      "iteration = 2000 grad = [ 2.26398223e-04  6.17849756e-05 -1.69331955e-05] ||grad|| = 0.00023528763609532866\n",
      "iteration = 1000 grad = [-0.02880901  0.00119139 -0.03245927] ||grad|| = 0.04341639091110138\n",
      "iteration = 2000 grad = [-0.01558297  0.00059598 -0.01756981] ||grad|| = 0.02349217708886017\n",
      "iteration = 3000 grad = [-0.00937304  0.00033057 -0.01057646] ||grad|| = 0.014135938244381984\n",
      "iteration = 4000 grad = [-0.00607841  0.00020431 -0.00686807] ||grad|| = 0.00917383504799914\n",
      "iteration = 5000 grad = [-0.00414947  0.00013445 -0.00468974] ||grad|| = 0.006263375447296787\n",
      "iteration = 6000 grad = [-2.93216530e-03  9.20564376e-05 -3.31203447e-03] ||grad|| = 0.004424436693752644\n",
      "iteration = 7000 grad = [-2.11853231e-03  6.53974201e-05 -2.39344950e-03] ||grad|| = 0.0031970387114337883\n",
      "iteration = 8000 grad = [-1.55754865e-03  4.70230833e-05 -1.75798393e-03] ||grad|| = 0.0023491863345891546\n",
      "iteration = 9000 grad = [-1.15546665e-03  3.50302920e-05 -1.30610957e-03] ||grad|| = 0.0017442054062756496\n",
      "iteration = 10000 grad = [-8.66921890e-04  2.57900344e-05 -9.78726996e-04] ||grad|| = 0.0013077175620263013\n",
      "iteration = 11000 grad = [-6.54055510e-04  1.92462484e-05 -7.37983745e-04] ||grad|| = 0.0009862956133853975\n",
      "iteration = 12000 grad = [-4.95628750e-04  1.44785914e-05 -5.59043416e-04] ||grad|| = 0.0007472529883803992\n",
      "iteration = 13000 grad = [-3.76231453e-04  1.10947410e-05 -4.24919234e-04] ||grad|| = 0.0005676526709033346\n",
      "iteration = 14000 grad = [-2.87044237e-04  8.36260888e-06 -3.23862192e-04] ||grad|| = 0.00043284067120572954\n",
      "iteration = 15000 grad = [-2.19292670e-04  6.35265941e-06 -2.47322120e-04] ||grad|| = 0.0003306022725149504\n",
      "iteration = 16000 grad = [-1.67405883e-04  4.92427906e-06 -1.89126723e-04] ||grad|| = 0.0002526220404944518\n",
      "iteration = 17000 grad = [-1.27949750e-04  3.81775784e-06 -1.44781482e-04] ||grad|| = 0.0001932547315523334\n",
      "iteration = 18000 grad = [-9.77631247e-05  2.98845733e-06 -1.10916503e-04] ||grad|| = 0.00014788181146074302\n",
      "iteration = 19000 grad = [-7.47485474e-05  2.33844669e-06 -8.50232591e-05] ||grad|| = 0.00011323324714308905\n",
      "iteration = 20000 grad = [-5.69877404e-05  1.87612616e-06 -6.51948446e-05] ||grad|| = 8.661114344293375e-05\n",
      "iteration = 21000 grad = [-4.38579441e-05  1.40525127e-06 -5.00224762e-05] ||grad|| = 6.654128126607822e-05\n",
      "iteration = 22000 grad = [-3.31211170e-05  1.20335051e-06 -3.83420941e-05] ||grad|| = 5.0681087403382124e-05\n",
      "iteration = 23000 grad = [-2.60884829e-05  7.62229039e-07 -2.94641764e-05] ||grad|| = 3.936149929317415e-05\n",
      "iteration = 24000 grad = [-1.96603560e-05  6.73452114e-07 -2.25980277e-05] ||grad|| = 2.9960874352344363e-05\n",
      "iteration = 25000 grad = [-1.49759724e-05  5.42608148e-07 -1.73315396e-05] ||grad|| = 2.2911927856133416e-05\n",
      "iteration = 26000 grad = [-1.16752837e-05  3.73953033e-07 -1.33169258e-05] ||grad|| = 1.771419212603977e-05\n",
      "iteration = 27000 grad = [-9.11768843e-06  2.49457987e-07 -1.02306787e-05] ||grad|| = 1.3706248885412138e-05\n",
      "iteration = 28000 grad = [-7.01672399e-06  1.88714591e-07 -7.86034290e-06] ||grad|| = 1.0538264526557658e-05\n",
      "alpha = 0.0001 f-score = 0.8805346700083543\n",
      "iteration = 1000 grad = [-0.03097592 -0.00448344 -0.01128441] ||grad|| = 0.03327081016810547\n",
      "iteration = 2000 grad = [-0.00534417 -0.00079753 -0.00196814] ||grad|| = 0.005750630206951263\n",
      "iteration = 3000 grad = [-0.00108884 -0.00016822 -0.00038272] ||grad|| = 0.0011663388708196226\n",
      "iteration = 4000 grad = [-1.86808134e-04 -2.89824642e-05 -6.53464675e-05] ||grad|| = 0.00020001855634824007\n",
      "iteration = 1000 grad = [ 5.64808811e-04  1.51919133e-04 -4.20183726e-05] ||grad|| = 0.0005863906206274652\n",
      "iteration = 1000 grad = [-0.05494226 -0.00591766 -0.02773419] ||grad|| = 0.06182925044401697\n",
      "iteration = 2000 grad = [-0.01764792 -0.0020042  -0.00892126] ||grad|| = 0.019875984027602114\n",
      "iteration = 3000 grad = [-0.00674963 -0.00077772 -0.00343286] ||grad|| = 0.007612287571033169\n",
      "iteration = 4000 grad = [-0.00288549 -0.00035198 -0.00140379] ||grad|| = 0.0032280933307387164\n",
      "iteration = 5000 grad = [-0.00117606 -0.00014935 -0.00055158] ||grad|| = 0.0013075359561869062\n",
      "iteration = 6000 grad = [-4.54546150e-04 -5.81834730e-05 -2.11739129e-04] ||grad|| = 0.0005048078623900862\n",
      "iteration = 7000 grad = [-1.76569450e-04 -2.27786697e-05 -8.16203896e-05] ||grad|| = 0.00019585077588158401\n",
      "iteration = 8000 grad = [-6.70910004e-05 -8.65926044e-06 -3.10044377e-05] ||grad|| = 7.441411346229317e-05\n",
      "iteration = 9000 grad = [-2.56233643e-05 -3.34613553e-06 -1.16936307e-05] ||grad|| = 2.8363610807091313e-05\n",
      "alpha = 0.001 f-score = 0.8708182665424046\n",
      "iteration = 1000 grad = [-3.21031067e-04 -5.25792956e-05 -8.68834935e-05] ||grad|| = 0.00033671095844264545\n",
      "alpha = 0.01 f-score = 0.8538759415027164\n",
      "iteration = 1000 grad = [-4.79835837e-05  9.40267255e-06 -8.98587906e-05] ||grad|| = 0.00010230071750037647\n",
      "alpha = 0.1 f-score = 0.5701581027667985\n",
      "alpha = 1.0 f-score = 0.4401560758082497\n",
      "Best params: 0.0001 0.8805346700083543\n",
      "iteration = 1000 grad = [-0.04858696 -0.00416815 -0.02879286] ||grad|| = 0.05663121390538801\n",
      "iteration = 2000 grad = [-0.02137928 -0.00194758 -0.01279128] ||grad|| = 0.024989668173431498\n",
      "iteration = 3000 grad = [-0.01134127 -0.00108627 -0.00675712] ||grad|| = 0.013246245900922743\n",
      "iteration = 4000 grad = [-0.00657159 -0.00064434 -0.00391626] ||grad|| = 0.007677116182272437\n",
      "iteration = 5000 grad = [-0.00400288 -0.00039458 -0.00239836] ||grad|| = 0.004683038647463299\n",
      "iteration = 6000 grad = [-0.00253615 -0.00025208 -0.0015195 ] ||grad|| = 0.002967233933409359\n",
      "iteration = 7000 grad = [-0.0016654  -0.00017155 -0.00097776] ||grad|| = 0.001938817178850514\n",
      "iteration = 8000 grad = [-0.00108981 -0.00011513 -0.00063012] ||grad|| = 0.0012641127700365729\n",
      "iteration = 9000 grad = [-7.05753630e-04 -7.49897923e-05 -4.06987002e-04] ||grad|| = 0.0008181381762257418\n",
      "iteration = 10000 grad = [-4.58983029e-04 -4.89834261e-05 -2.64106273e-04] ||grad|| = 0.0005318053409089748\n",
      "iteration = 11000 grad = [-2.98795774e-04 -3.19958992e-05 -1.71621582e-04] ||grad|| = 0.00034605869392349045\n",
      "iteration = 12000 grad = [-1.94947371e-04 -2.09692836e-05 -1.11655718e-04] ||grad|| = 0.00022563507670418987\n",
      "iteration = 13000 grad = [-1.27975920e-04 -1.40066408e-05 -7.23830848e-05] ||grad|| = 0.00014769337522747714\n",
      "iteration = 14000 grad = [-8.29616656e-05 -9.13288259e-06 -4.67262670e-05] ||grad|| = 9.565245179726992e-05\n"
     ]
    }
   ],
   "source": [
    "process_with_solver(X, y, 'gradient', 0.1, 0.01, debug_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_with_solver(X, y, 'newton', 0.1, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
